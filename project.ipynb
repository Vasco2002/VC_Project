{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# importing a module with utilities for displaying stats and data\n",
    "import sys\n",
    "sys.path.insert(1, 'util')\n",
    "import vcpi_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCKS = 20\n",
    "IMG_SIZE = 32\n",
    "EPOCHS = 60\n",
    "\n",
    "PATH_TRAINING_SET = \"data/train_images/GTSRB/Final_Training/Images\"\n",
    "PATH_TEST_SET = \"data/test_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta secção define várias funções auxiliares utilizadas para treinar e avaliar os modelos:\n",
    "- A função `train` é responsável por treinar o modelo durante várias épocas, calculando a perda e a precisão tanto nos dados de treinamento quanto nos de validação. \n",
    "\n",
    "- A classe `Early_Stopping` é utilizado para interromper o treinamento prematuramente se não houver melhoria na perda de validação num determinado número de épocas.\n",
    "\n",
    "- A função `evaluate` é responsável por avaliar o desempenho do modelo num conjunto de dados de teste, calculando a precisão geral do modelo.\n",
    "\n",
    "- A classe `Conv` define a arquitetura da rede utilizada, composta por várias camadas convolucionais e totalmente conectadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, epochs, loss_fn, optimizer,\n",
    "           scheduler, early_stopper, save_prefix = 'model'):\n",
    "\n",
    "    history = {}\n",
    "    history['accuracy'] = []\n",
    "    history['val_acc'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['loss'] = []\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        model.train()\n",
    "        start_time = time.time() \n",
    "        correct = 0\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, targets) in enumerate(train_loader, 0):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.detach()\n",
    "            correct += (predicted == targets).sum()\n",
    "\n",
    "        model.eval()\n",
    "        v_correct = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i,t in val_loader:\n",
    "                i = i.to(device)\n",
    "                t = t.to(device)\n",
    "                o = model(i)\n",
    "                _,p = torch.max(o,1)\n",
    "                \n",
    "                #with torch.no_grad():\n",
    "                val_loss += loss_fn(o, t)\n",
    "\n",
    "                v_correct += (p == t).sum()\n",
    "\n",
    "        old_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_loss)\n",
    "        new_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        if old_lr != new_lr:\n",
    "            print('==> Learning rate updated: ', old_lr, ' -> ', new_lr)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        accuracy = 100 * correct / len(train_loader.dataset)\n",
    "        v_accuracy = 100 * v_correct / len(val_loader.dataset)\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        stop_time = time.time()\n",
    "        print(f'Epoch: {epoch:03d}; Loss: {epoch_loss:0.6f}; Accuracy: {accuracy:0.4f}; Val Loss: {val_loss:0.6f}; Val Acc: {v_accuracy:0.4f}; Elapsed time: {(stop_time - start_time):0.4f}')\n",
    "        history['accuracy'].append(accuracy.cpu().numpy())\n",
    "        history['val_acc'].append(v_accuracy.cpu().numpy())\n",
    "        history['val_loss'].append(val_loss.cpu().detach().numpy())\n",
    "        history['loss'].append(epoch_loss.cpu().detach().numpy())\n",
    " \n",
    "        ###### Saving ######\n",
    "        if val_loss < best_val_loss :\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model':model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict()\n",
    "                },\n",
    "                f'models/{save_prefix}.pt')\n",
    "\n",
    "        if early_stopper(val_loss):\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "        \n",
    "    print('Finished Training')\n",
    "\n",
    "    return(history)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "\n",
    "    # sets the model in evaluation mode.\n",
    "    # although our model does not have layers which behave differently during training and evaluation\n",
    "    # this is a good practice as the models architecture may change in the future\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, targets) in enumerate(data_loader):\n",
    "\n",
    "            # forward pass, compute the output of the model for the current batch\n",
    "            outputs = model(images.to(device))\n",
    "\n",
    "            # \"max\" returns a namedtuple (values, indices) where values is the maximum \n",
    "            # value of each row of the input tensor in the given dimension dim; \n",
    "            # indices is the index location of each maximum value found (argmax).\n",
    "            # the argmax effectively provides the predicted class number        \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            correct += (preds.cpu() == targets).sum()\n",
    "\n",
    "    return (correct / len(data_loader.dataset)).item()\n",
    "\n",
    "\n",
    "class Conv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(16)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(32)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(2)\n",
    "\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(32, 48, 3)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(48)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "\n",
    "        self.conv4 = torch.nn.Conv2d(48, 48, 3)\n",
    "        self.bn4 = torch.nn.BatchNorm2d(48)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(2)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(1200, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):    \n",
    "        \n",
    "        # input = (bs, 3, 32, 32)\n",
    "        x = self.conv1(x) # -> (bs, 16, 30, 30)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x) # -> (bs, 32, 28, 28)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool1(x) # -> (bs, 32, 14, 14)\n",
    "        \n",
    "        x = self.conv3(x) # -> (bs, 48, 12, 12)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x) # -> (bs, 48, 10, 10)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.maxpool2(x) # -> (bs, 48, 5, 5)\n",
    "        \n",
    "        x = torch.flatten(x,1) # -> (bs, 48 * 5 * 5 = 1200)\n",
    "        x = self.fc1(x)        # -> (bs, num_classes)\n",
    "\n",
    "        return(x)\n",
    "\n",
    "\n",
    "class Early_Stopping():\n",
    "\n",
    "    def __init__(self, patience = 3, min_delta = 0.00001):\n",
    "\n",
    "        self.patience = patience \n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.min_delta\n",
    "        self.min_val_loss = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "\n",
    "        # improvement\n",
    "        if val_loss + self.min_delta < self.min_val_loss:\n",
    "            self.min_val_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "        # no improvement            \n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter > self.patience:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "def build_confusion_matrix(model, dataset):\n",
    "\n",
    "    preds = []\n",
    "    ground_truth = []\n",
    "\n",
    "    for images, targets in dataset:\n",
    "\n",
    "        predictions = model(images.to(device))\n",
    "        preds_sparse = [np.argmax(x) for x in predictions.cpu().detach().numpy()]\n",
    "        preds.extend(preds_sparse)\n",
    "        ground_truth.extend(targets.numpy())\n",
    "\n",
    "    vcpi_util.show_confusion_matrix(ground_truth, preds, len(test_set.classes)) \n",
    "\n",
    "def build_confusion_matrix2(model, dataset, class_names):\n",
    "    preds = []\n",
    "    ground_truth = []\n",
    "\n",
    "    for images, targets in dataset:\n",
    "        predictions = model(images.to(device))\n",
    "        preds_sparse = [np.argmax(x) for x in predictions.cpu().detach().numpy()]\n",
    "        preds.extend(preds_sparse)\n",
    "        ground_truth.extend(targets.numpy())\n",
    "\n",
    "    num_classes = len(class_names) if class_names else len(set(ground_truth))\n",
    "    vcpi_util.show_confusion_matrix(ground_truth, preds, len(test_set.classes))\n",
    "\n",
    "\n",
    "class TransfDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.dataset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento de Dados\n",
    "\n",
    "Nesta secção, completamos a preparação dos dados, carregando os conjuntos de dados de treinamento, validação e teste com as suas respetivas transformações base.\n",
    "\n",
    "É feito um shuffle nos dados de treino e é colocado 30% dos dados de treino como dados de validação. As transformações na variável *base_transform* são realizadas em todos os datasets (treino, teste e validação) e as transformações na variável *transform* são realizadas exclusivamente no dataset de treino.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "base_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.ImageFolder(root=PATH_TEST_SET, transform = base_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = BATCH_SIZE)\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "rtrain_set = torchvision.datasets.ImageFolder(root=PATH_TRAINING_SET, transform = base_transform)\n",
    "train_set, val_set = torch.utils.data.random_split(rtrain_set, [0.7,0.3], generator=generator1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo *model12fr*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.RandomPerspective(distortion_scale=0.3,p=1.0),\n",
    "    v2.RandomAffine(degrees=3, translate=(0.03,0.03)),\n",
    "    v2.RandomRotation(2, v2.InterpolationMode.BILINEAR),\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.4, saturation=0.3),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(TransfDataset(train_set,transform), batch_size = BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_loader))\n",
    "vcpi_util.show_images(4,8,images,targets,rtrain_set.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta secção realizamos o treinamento e a avaliação do modelo. Primeiro, inicializamos o modelo e o movemos para o dispositivo de computação adequado. Em seguida, configuramos o otimizador do tipo Adam, a função de perda e o critério de parada antecipada. Depois, treinamos o modelo chamando a função *train*, passando os carregadores de dados de treinamento e validação, juntamente com o número de épocas e o prefixo para guardar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv(len(rtrain_set.classes))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor = 0.1, patience=3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "early_stop = Early_Stopping(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(\n",
    "    model, train_loader, val_loader,\n",
    "    EPOCHS, loss_fn, optimizer, scheduler, early_stop, 'model12fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Por fim, depois do modelo ser treinado, avaliamos o desempenho do modelo no conjunto de dados de teste usando a função *evaluate*, obtendo, assim, o resultado da precisão do nosso modelo perante o dataset de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo *model13fr*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.RandomPerspective(distortion_scale=0.3,p=1.0),\n",
    "    v2.RandomAffine(degrees=3, translate=(0.03,0.03)),\n",
    "    v2.RandomRotation(2, v2.InterpolationMode.BILINEAR),\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.4, saturation=0.3),\n",
    "    v2.RandomErasing(p=1, scale=(0.03, 0.05), ratio=(0.3, 3.3), value='random'),\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(TransfDataset(train_set,transform), batch_size = BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_loader))\n",
    "vcpi_util.show_images(4,8,images,targets,rtrain_set.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv(len(rtrain_set.classes))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor = 0.1, patience=3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "early_stop = Early_Stopping(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(\n",
    "    model, train_loader, val_loader,\n",
    "    EPOCHS, loss_fn, optimizer, scheduler, early_stop, 'model13fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo *model17fr*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.RandomPerspective(distortion_scale=0.3,p=1.0),\n",
    "    v2.RandomAffine(degrees=4, translate=(0.03,0.03)),\n",
    "    v2.RandomRotation(3, v2.InterpolationMode.BILINEAR),\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.3),\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(TransfDataset(train_set,transform), batch_size = BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_loader))\n",
    "vcpi_util.show_images(4,8,images,targets,rtrain_set.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv(len(rtrain_set.classes))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor = 0.1, patience=3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "early_stop = Early_Stopping(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(\n",
    "    model, train_loader, val_loader,\n",
    "    EPOCHS, loss_fn, optimizer, scheduler, early_stop, 'model17fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo *model11fr*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.RandomPerspective(distortion_scale=0.2,p=1.0),\n",
    "    v2.RandomAffine(degrees=3, translate=(0.03,0.03)),\n",
    "    v2.RandomRotation(3, v2.InterpolationMode.BILINEAR),\n",
    "    v2.ColorJitter(brightness=0.1, contrast=0.2, saturation=0.2),\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(TransfDataset(train_set,transform), batch_size = BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_loader))\n",
    "vcpi_util.show_images(4,8,images,targets,rtrain_set.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv(len(rtrain_set.classes))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor = 0.1, patience=3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "early_stop = Early_Stopping(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(\n",
    "    model, train_loader, val_loader,\n",
    "    EPOCHS, loss_fn, optimizer, scheduler, early_stop, 'model11fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo *model9fr*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.RandomAffine(degrees=3, translate=(0.03,0.03)),\n",
    "    v2.RandomRotation(3, v2.InterpolationMode.BILINEAR),\n",
    "    v2.ColorJitter(brightness=0.1, contrast=0.2, saturation=0.2),\n",
    "])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(TransfDataset(train_set,transform), batch_size = BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_loader))\n",
    "vcpi_util.show_images(4,8,images,targets,rtrain_set.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv(len(rtrain_set.classes))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor = 0.1, patience=3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "early_stop = Early_Stopping(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train(\n",
    "    model, train_loader, val_loader,\n",
    "    EPOCHS, loss_fn, optimizer, scheduler, early_stop, 'model9fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
